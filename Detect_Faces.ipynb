{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "import copy \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = Path(__file__).resolve()\n",
    "ROOT = FILE.parents[0]  # YOLOv5 root directory\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import letterbox, img_formats, vid_formats, LoadImages, LoadStreams\n",
    "from utils.general import check_img_size, non_max_suppression_face, apply_classifier, scale_coords, xyxy2xywh, \\\n",
    "    strip_optimizer, set_logging, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized\n",
    "\n",
    "\n",
    "def load_model(weights, device):\n",
    "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale coords (xyxy) from img1_shape to img0_shape\n",
    "def scale_coords_landmarks(img1_shape, coords, img0_shape, ratio_pad=None):\n",
    "    if ratio_pad is None:  # calculate from img0_shape\n",
    "        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new\n",
    "        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding\n",
    "    else:\n",
    "        gain = ratio_pad[0][0]\n",
    "        pad = ratio_pad[1]\n",
    "\n",
    "    coords[:, [0, 2, 4, 6, 8]] -= pad[0]  # x padding\n",
    "    coords[:, [1, 3, 5, 7, 9]] -= pad[1]  # y padding\n",
    "    coords[:, :10] /= gain  \n",
    "    #clip_coords(coords, img0_shape)\n",
    "    coords[:, 0].clamp_(0, img0_shape[1])  # x1\n",
    "    coords[:, 1].clamp_(0, img0_shape[0])  # y1\n",
    "    coords[:, 2].clamp_(0, img0_shape[1])  # x2\n",
    "    coords[:, 3].clamp_(0, img0_shape[0])  # y2\n",
    "    coords[:, 4].clamp_(0, img0_shape[1])  # x3\n",
    "    coords[:, 5].clamp_(0, img0_shape[0])  # y3\n",
    "    coords[:, 6].clamp_(0, img0_shape[1])  # x4\n",
    "    coords[:, 7].clamp_(0, img0_shape[0])  # y4\n",
    "    coords[:, 8].clamp_(0, img0_shape[1])  # x5\n",
    "    coords[:, 9].clamp_(0, img0_shape[0])  # y5\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "def show_results(img, xyxy, conf, landmarks, class_num):\n",
    "    h,w,c = img.shape\n",
    "    tl = 1 or round(0.002 * (h + w) / 2) + 1  # line/font thickness\n",
    "    x1 = int(xyxy[0])\n",
    "    y1 = int(xyxy[1])\n",
    "    x2 = int(xyxy[2])\n",
    "    y2 = int(xyxy[3])\n",
    "    img = img.copy()\n",
    "    \n",
    "    cv2.rectangle(img, (x1,y1), (x2, y2), (0,255,0), thickness=tl, lineType=cv2.LINE_AA)\n",
    "\n",
    "    clors = [(255,0,0),(0,255,0),(0,0,255),(255,255,0),(0,255,255)]\n",
    "\n",
    "    for i in range(5):\n",
    "        point_x = int(landmarks[2 * i])\n",
    "        point_y = int(landmarks[2 * i + 1])\n",
    "        cv2.circle(img, (point_x, point_y), tl+1, clors[i], -1)\n",
    "\n",
    "    tf = max(tl - 1, 1)  # font thickness\n",
    "    label = str(conf)[:5]\n",
    "    cv2.putText(img, label, (x1, y1 - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "\n",
    "def detect(\n",
    "    model,\n",
    "    source,\n",
    "    device,\n",
    "    project,\n",
    "    name,\n",
    "    exist_ok,\n",
    "    save_img,\n",
    "    view_img\n",
    "):\n",
    "    # Load model\n",
    "    img_size = 640\n",
    "    conf_thres = 0.6\n",
    "    iou_thres = 0.5\n",
    "    imgsz=(640, 640)\n",
    "     # Directories\n",
    "    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    is_file = Path(source).suffix[1:] in (img_formats + vid_formats)\n",
    "    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "    webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)\n",
    "    # Dataloader\n",
    "    if webcam:\n",
    "        print('loading streams:', source)\n",
    "        dataset = LoadStreams(source, img_size=imgsz)\n",
    "        bs = 1  # batch_size\n",
    "    else:\n",
    "        print('loading images', source)\n",
    "        dataset = LoadImages(source, img_size=imgsz)\n",
    "        bs = 1  # batch_size\n",
    "    vid_path, vid_writer = [None] * bs, [None] * bs\n",
    "    \n",
    "    for path, im, im0s, vid_cap in dataset:\n",
    "        \n",
    "        if len(im.shape) == 4:\n",
    "            orgimg = np.squeeze(im.transpose(0, 2, 3, 1), axis= 0)\n",
    "        else:\n",
    "            orgimg = im.transpose(1, 2, 0)\n",
    "        \n",
    "        orgimg = cv2.cvtColor(orgimg, cv2.COLOR_BGR2RGB)\n",
    "        img0 = copy.deepcopy(orgimg)\n",
    "        h0, w0 = orgimg.shape[:2]  # orig hw\n",
    "        r = img_size / max(h0, w0)  # resize image to img_size\n",
    "        if r != 1:  # always resize down, only resize up if training with augmentation\n",
    "            interp = cv2.INTER_AREA if r < 1  else cv2.INTER_LINEAR\n",
    "            img0 = cv2.resize(img0, (int(w0 * r), int(h0 * r)), interpolation=interp)\n",
    "\n",
    "        imgsz = check_img_size(img_size, s=model.stride.max())  # check img_size\n",
    "\n",
    "        img = letterbox(img0, new_shape=imgsz)[0]\n",
    "        # Convert from w,h,c to c,w,h\n",
    "        img = img.transpose(2, 0, 1).copy()\n",
    "\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "            # Inference\n",
    "        pred = model(img)[0]\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression_face(pred, conf_thres, iou_thres)\n",
    "        print(len(pred[0]), 'face' if len(pred[0]) == 1 else 'faces')\n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            \n",
    "            if webcam:  # batch_size >= 1\n",
    "                p, im0, frame = path[i], im0s[i].copy(), dataset.count\n",
    "            else:\n",
    "                p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "            \n",
    "            p = Path(p)  # to Path\n",
    "            save_path = str(Path(save_dir) / p.name)  # im.jpg\n",
    "            faces_detected=0\n",
    "            total_faces=0\n",
    "\n",
    "            if len(det):\n",
    "                faces_detected=1\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "                 # Print results\n",
    "                \n",
    "                for c in det[:, -1].unique():\n",
    "\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    print(n,\"\\n\")\n",
    "\n",
    "                det[:, 5:15] = scale_coords_landmarks(img.shape[2:], det[:, 5:15], im0.shape).round()\n",
    "\n",
    "                for j in range(det.size()[0]):\n",
    "                    xyxy = det[j, :4].view(-1).tolist()\n",
    "                    conf = det[j, 4].cpu().numpy()\n",
    "                    landmarks = det[j, 5:15].view(-1).tolist()\n",
    "                    class_num = det[j, 15].cpu().numpy()\n",
    "                    \n",
    "                    im0 = show_results(im0, xyxy, conf, landmarks, class_num)\n",
    "            print(im0.shape)        \n",
    "            top_right = (im0.shape[1] - 10, 10) \n",
    "            bottom_left = (im0.shape[1] - 420, 80)  \n",
    "            cv2.rectangle(im0, bottom_left, top_right, (255, 255, 255), thickness=cv2.FILLED)\n",
    "          \n",
    "            annotation = f'Faces Detected: {faces_detected}, Total Faces: {total_faces}'\n",
    "            im0= cv2.putText(im0, annotation, (im0.shape[1] - 250, 60), cv2.FONT_HERSHEY_SIMPLEX ,1,(0,0,255),2)\n",
    "            if view_img:\n",
    "                cv2.imshow('result', im0)\n",
    "                k = cv2.waitKey(1)\n",
    "                 # Save results (image with detections)\n",
    "            if save_img:\n",
    "                if dataset.mode == 'image':\n",
    "                    cv2.imwrite(save_path, im0)\n",
    "                else:  # 'video' or 'stream'\n",
    "                    if vid_path[i] != save_path:  # new video\n",
    "                        vid_path[i] = save_path\n",
    "                        if isinstance(vid_writer[i], cv2.VideoWriter):\n",
    "                            vid_writer[i].release()  # release previous video writer\n",
    "                        if vid_cap:  # video\n",
    "                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                        else:  # stream\n",
    "                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                        save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos\n",
    "                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "                    try:\n",
    "                        vid_writer[i].write(im0)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--weights', nargs='+', type=str, default='runs/train/exp5/weights/last.pt', help='model.pt path(s)')\n",
    "    parser.add_argument('--source', type=str, default='0', help='source')  # file/folder, 0 for webcam\n",
    "    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n",
    "    parser.add_argument('--project', default=ROOT / 'runs/detect', help='save results to project/name')\n",
    "    parser.add_argument('--name', default='exp', help='save results to project/name')\n",
    "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
    "    parser.add_argument('--save-img', action='store_true', help='save results')\n",
    "    parser.add_argument('--view-img', action='store_true', help='show results')\n",
    "    opt = parser.parse_args()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = load_model(opt.weights, device)\n",
    "    detect(model, opt.source, device, opt.project, opt.name, opt.exist_ok, opt.save_img, opt.view_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This  is the main ipynb file to detect the faces from a video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here using yolo v5 trained on multiple face data which you can find on my github\n",
    ">> github.com\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the output video with the name video.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
